{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQC-qClbPouy",
    "outputId": "56ed328a-cbdb-4c67-a8cb-11802ea8617d"
   },
   "outputs": [],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lj55LdsGPwwF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "QWXj7_X1P2sq",
    "outputId": "fa1ebd39-ce0e-43ac-d00e-44e8de205bfd"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('marathiData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss_fZU6lP35m"
   },
   "outputs": [],
   "source": [
    "def getStopWords():\n",
    "  with open('./stopwords-mr.txt','r') as f:\n",
    "    stopwords=f.read()\n",
    "    stopwords=stopwords.split('\\n')\n",
    "    return stopwords\n",
    "\n",
    "stopWords=getStopWords()\n",
    "\n",
    "stop_words = stopWords\n",
    "suffixes = ['ता', 'ते', 'तो', 'ल', 'ना', 'णे', 'त', 'य']\n",
    "def stem_marathi_word(word):\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "noun_suffixes = ['आणि', 'े', 'ा', 'नी', 'ची', 'मधील', 'हवे', 'ची', 'चा']\n",
    "verb_suffixes = ['त', 'तो', 'ते', 'ली', 'ला', 'ले', 'णार', 'त आहे', 'त असतील']\n",
    "def lemmatize_marathi(word):\n",
    "    # Rule-based stripping of verb suffixes\n",
    "    for suffix in verb_suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]  # Stripping the suffix\n",
    "    # Rule-based stripping of noun suffixes\n",
    "    for suffix in noun_suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "def preprocess_text(text, use_stemming=False, use_lemmatization=False):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove numbers and special characters\n",
    "    cleaned_text = ''.join(char for char in text if ('\\u0900' <= char <= '\\u097F') or char.isspace())\n",
    "\n",
    "    # Remove stop words\n",
    "    cleaned_text = ' '.join([word for word in cleaned_text.split() if word not in stop_words])\n",
    "\n",
    "    # Apply stemming or lemmatization if specified\n",
    "    if use_stemming:\n",
    "        cleaned_text = ' '.join([stem_marathi_word(word) for word in cleaned_text.split()])\n",
    "    elif use_lemmatization:\n",
    "        cleaned_text = ' '.join([lemmatize_marathi(word) for word in cleaned_text.split()])\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "df['translated_source'] = df['translated_source'].apply(lambda x: preprocess_text(x))\n",
    "df['translated_plagiarism'] = df['translated_plagiarism'].apply(lambda x: preprocess_text(x))\n",
    "df['stemmed_srcText']= df['translated_source'].apply(lambda x: preprocess_text(x,use_stemming=True, use_lemmatization=True))\n",
    "df['stemmed_plagText']=df['translated_plagiarism'].apply(lambda x: preprocess_text(x,use_stemming=True, use_lemmatization=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "sdVs7AOAP5gh",
    "outputId": "14d5b9be-2b68-43ac-e4a5-1ee5843467f2"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXzYOkMKP6sZ"
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer400 = TfidfVectorizer(max_features=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjX-Fni5P-6p"
   },
   "outputs": [],
   "source": [
    "tfidf_embeddings_source400 = tfidf_vectorizer400.fit_transform(df['stemmed_srcText'].tolist()).toarray()\n",
    "tfidf_embeddings_plag400=tfidf_vectorizer400.fit_transform(df['stemmed_plagText'].tolist()).toarray()\n",
    "\n",
    "tfidf_embeddings400 = tfidf_embeddings_source400 - tfidf_embeddings_plag400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knohJZLyQIDY"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train400, X_test400, y_train400, y_test400 = train_test_split(\n",
    "    tfidf_embeddings400, df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train400 = scaler.fit_transform(X_train400)\n",
    "X_test400 = scaler.transform(X_test400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmMf1NDsgDjf"
   },
   "source": [
    "# **XGBOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "1_asJpOhQoIe",
    "outputId": "29195a9e-510e-4114-9f97-b673f606b942"
   },
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize the FLAML AutoML instance\n",
    "automl = AutoML()\n",
    "\n",
    "# Set the training parameters\n",
    "automl_settings = {\n",
    "    \"time_budget\": 1000,  # Total running time in seconds\n",
    "    \"metric\": 'accuracy',  # Evaluation metric\n",
    "    \"task\": 'classification',  # Task type\n",
    "    \"n_jobs\": -1,\n",
    "    \"estimator_list\": [\"xgboost\"],\n",
    "    \"early_stop\": True\n",
    "\n",
    "}\n",
    "\n",
    "# Fit the FLAML AutoML instance on the training data\n",
    "automl.fit(X_train400, y_train400, **automl_settings)\n",
    "\n",
    "# Display the best model found\n",
    "print(\"Best model:\", automl.best_estimator)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = automl.predict(X_test400)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "metrics_test = {\n",
    "    \"Accuracy\": accuracy_score(y_test400, y_test_pred) * 100,\n",
    "    \"Precision\": precision_score(y_test400, y_test_pred) * 100,\n",
    "    \"Recall\": recall_score(y_test400, y_test_pred) * 100,\n",
    "    \"F1 Score\": f1_score(y_test400, y_test_pred) * 100,\n",
    "    \"Confusion Matrix\": confusion_matrix(y_test400, y_test_pred)\n",
    "}\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for metric, value in metrics_test.items():\n",
    "    if metric != \"Confusion Matrix\":\n",
    "        print(f\"{metric}: {value:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{metric}:\\n{value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47AhknNKVW1M"
   },
   "source": [
    "# **LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "q6W7dD_LVWnZ",
    "outputId": "fe04ce0e-9fd6-4dff-be67-5890d93a053d"
   },
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize the FLAML AutoML instance\n",
    "automl = AutoML()\n",
    "\n",
    "# Set the training parameters\n",
    "automl_settings = {\n",
    "    \"time_budget\": 1000,  # Total running time in seconds\n",
    "    \"metric\": 'accuracy',  # Evaluation metric\n",
    "    \"task\": 'classification',  # Task type\n",
    "    \"n_jobs\": -1,\n",
    "    \"estimator_list\": [\"lgbm\"],\n",
    "    \"early_stop\": True\n",
    "\n",
    "}\n",
    "\n",
    "# Fit the FLAML AutoML instance on the training data\n",
    "automl.fit(X_train400, y_train400, **automl_settings)\n",
    "\n",
    "# Display the best model found\n",
    "print(\"Best model:\", automl.best_estimator)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = automl.predict(X_test400)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "metrics_test = {\n",
    "    \"Accuracy\": accuracy_score(y_test400, y_test_pred) * 100,\n",
    "    \"Precision\": precision_score(y_test400, y_test_pred) * 100,\n",
    "    \"Recall\": recall_score(y_test400, y_test_pred) * 100,\n",
    "    \"F1 Score\": f1_score(y_test400, y_test_pred) * 100,\n",
    "    \"Confusion Matrix\": confusion_matrix(y_test400, y_test_pred)\n",
    "}\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for metric, value in metrics_test.items():\n",
    "    if metric != \"Confusion Matrix\":\n",
    "        print(f\"{metric}: {value:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{metric}:\\n{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTVLuusXZ8h8"
   },
   "source": [
    "# **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ltNhfRSYQ2iG",
    "outputId": "4b0c3822-252b-4268-9bf9-5769f43efc9f"
   },
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize the FLAML AutoML instance\n",
    "automl = AutoML()\n",
    "\n",
    "# Set the training parameters\n",
    "automl_settings = {\n",
    "    \"time_budget\": 1000,  # Total running time in seconds\n",
    "    \"metric\": 'accuracy',  # Evaluation metric\n",
    "    \"task\": 'classification',  # Task type\n",
    "    \"n_jobs\": -1,\n",
    "    \"estimator_list\": [\"rf\"],\n",
    "    \"early_stop\": True\n",
    "\n",
    "}\n",
    "\n",
    "# Fit the FLAML AutoML instance on the training data\n",
    "automl.fit(X_train400, y_train400, **automl_settings)\n",
    "\n",
    "# Display the best model found\n",
    "print(\"Best model:\", automl.best_estimator)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = automl.predict(X_test400)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "metrics_test = {\n",
    "    \"Accuracy\": accuracy_score(y_test400, y_test_pred) * 100,\n",
    "    \"Precision\": precision_score(y_test400, y_test_pred) * 100,\n",
    "    \"Recall\": recall_score(y_test400, y_test_pred) * 100,\n",
    "    \"F1 Score\": f1_score(y_test400, y_test_pred) * 100,\n",
    "    \"Confusion Matrix\": confusion_matrix(y_test400, y_test_pred)\n",
    "}\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for metric, value in metrics_test.items():\n",
    "    if metric != \"Confusion Matrix\":\n",
    "        print(f\"{metric}: {value:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{metric}:\\n{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlKMpjnreYFM"
   },
   "source": [
    "# **SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tQF573U7eXtw",
    "outputId": "6a39d26c-e7cb-4da5-d576-c2406bfdfc2b"
   },
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize the FLAML AutoML instance\n",
    "automl = AutoML()\n",
    "\n",
    "# Set the training parameters\n",
    "automl_settings = {\n",
    "    \"time_budget\": 1000,  # Total running time in seconds\n",
    "    \"metric\": 'accuracy',  # Evaluation metric\n",
    "    \"task\": 'classification',  # Task type\n",
    "    \"n_jobs\": -1,\n",
    "    \"estimator_list\": [\"svc\"],\n",
    "    \"early_stop\": True\n",
    "\n",
    "}\n",
    "\n",
    "# Fit the FLAML AutoML instance on the training data\n",
    "automl.fit(X_train400, y_train400, **automl_settings)\n",
    "\n",
    "# Display the best model found\n",
    "print(\"Best model:\", automl.best_estimator)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = automl.predict(X_test400)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "metrics_test = {\n",
    "    \"Accuracy\": accuracy_score(y_test400, y_test_pred) * 100,\n",
    "    \"Precision\": precision_score(y_test400, y_test_pred) * 100,\n",
    "    \"Recall\": recall_score(y_test400, y_test_pred) * 100,\n",
    "    \"F1 Score\": f1_score(y_test400, y_test_pred) * 100,\n",
    "    \"Confusion Matrix\": confusion_matrix(y_test400, y_test_pred)\n",
    "}\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for metric, value in metrics_test.items():\n",
    "    if metric != \"Confusion Matrix\":\n",
    "        print(f\"{metric}: {value:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{metric}:\\n{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEXZcj-fihMF"
   },
   "source": [
    "# **Logistic Regression lrl2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "zicz-5H1ig8Q",
    "outputId": "a7fe505c-fb01-43ac-81ef-41c18cf0c877"
   },
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize the FLAML AutoML instance\n",
    "automl = AutoML()\n",
    "\n",
    "# Set the training parameters\n",
    "automl_settings = {\n",
    "    \"time_budget\": 1000,  # Total running time in seconds\n",
    "    \"metric\": 'accuracy',  # Evaluation metric\n",
    "    \"task\": 'classification',  # Task type\n",
    "    \"n_jobs\": -1,\n",
    "    \"estimator_list\": [\"lrl2\"],\n",
    "    \"early_stop\": True\n",
    "\n",
    "}\n",
    "\n",
    "# Fit the FLAML AutoML instance on the training data\n",
    "automl.fit(X_train400, y_train400, **automl_settings)\n",
    "\n",
    "# Display the best model found\n",
    "print(\"Best model:\", automl.best_estimator)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = automl.predict(X_test400)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "metrics_test = {\n",
    "    \"Accuracy\": accuracy_score(y_test400, y_test_pred) * 100,\n",
    "    \"Precision\": precision_score(y_test400, y_test_pred) * 100,\n",
    "    \"Recall\": recall_score(y_test400, y_test_pred) * 100,\n",
    "    \"F1 Score\": f1_score(y_test400, y_test_pred) * 100,\n",
    "    \"Confusion Matrix\": confusion_matrix(y_test400, y_test_pred)\n",
    "}\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for metric, value in metrics_test.items():\n",
    "    if metric != \"Confusion Matrix\":\n",
    "        print(f\"{metric}: {value:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{metric}:\\n{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRSxUtxQm0P5"
   },
   "source": [
    "# **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "X1Mx894xmz_q",
    "outputId": "152f89d9-b660-45e5-a7d9-c0e99f71089d"
   },
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize the FLAML AutoML instance\n",
    "automl = AutoML()\n",
    "\n",
    "# Set the training parameters\n",
    "automl_settings = {\n",
    "    \"time_budget\": 1000,  # Total running time in seconds\n",
    "    \"metric\": 'accuracy',  # Evaluation metric\n",
    "    \"task\": 'classification',  # Task type\n",
    "    \"n_jobs\": -1,\n",
    "    \"estimator_list\": [\"kneighbor\"],\n",
    "    \"early_stop\": True\n",
    "\n",
    "}\n",
    "\n",
    "# Fit the FLAML AutoML instance on the training data\n",
    "automl.fit(X_train400, y_train400, **automl_settings)\n",
    "\n",
    "# Display the best model found\n",
    "print(\"Best model:\", automl.best_estimator)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = automl.predict(X_test400)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "metrics_test = {\n",
    "    \"Accuracy\": accuracy_score(y_test400, y_test_pred) * 100,\n",
    "    \"Precision\": precision_score(y_test400, y_test_pred) * 100,\n",
    "    \"Recall\": recall_score(y_test400, y_test_pred) * 100,\n",
    "    \"F1 Score\": f1_score(y_test400, y_test_pred) * 100,\n",
    "    \"Confusion Matrix\": confusion_matrix(y_test400, y_test_pred)\n",
    "}\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for metric, value in metrics_test.items():\n",
    "    if metric != \"Confusion Matrix\":\n",
    "        print(f\"{metric}: {value:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{metric}:\\n{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki0o1396nazk"
   },
   "source": [
    "# **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "a2c_aNcZnaPk",
    "outputId": "2ab87a5d-c1ff-4c0b-ffb4-1d6f335e60b8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=100)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                           scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train400, y_train400)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "y_pred = best_model.predict(X_test400)\n",
    "\n",
    "accuracy = accuracy_score(y_test400, y_pred)\n",
    "precision = precision_score(y_test400, y_pred)\n",
    "recall = recall_score(y_test400, y_pred)\n",
    "f1 = f1_score(y_test400, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test400, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMp4l9-4oR_c"
   },
   "source": [
    "# **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "D4VFQC9-aHYH",
    "outputId": "4f03d793-7baf-4b41-fbcf-fbfdfc55bcab"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Configure Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                           scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the model using your data\n",
    "grid_search.fit(X_train400, y_train400)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test400)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test400, y_pred)\n",
    "precision = precision_score(y_test400, y_pred)\n",
    "recall = recall_score(y_test400, y_pred)\n",
    "f1 = f1_score(y_test400, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test400, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QpyOogApbLw"
   },
   "source": [
    "# **AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQED-TaKpAY5",
    "outputId": "f562f346-eba4-41cb-eb99-33e20ff5bb92"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the model\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# Set up the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0, 10],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=1), None]  # Decision stump or default estimator\n",
    "}\n",
    "\n",
    "# Configure Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                           scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the model using your data\n",
    "grid_search.fit(X_train400, y_train400)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test400)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test400, y_pred)\n",
    "precision = precision_score(y_test400, y_pred)\n",
    "recall = recall_score(y_test400, y_pred)\n",
    "f1 = f1_score(y_test400, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test400, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-owm6AzUpp9-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
