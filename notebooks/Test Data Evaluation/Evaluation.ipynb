{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0NAMaODPfqi",
    "outputId": "8fa5536f-e2cf-41f7-8a8a-09c130a93990"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRG3rYGcQSD9"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['#1 ID', '#2 ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HLKoJcLQ5FC"
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'Quality': 'label',\n",
    "    '#1 String': 'source_txt',\n",
    "    '#2 String': 'plagarism_txt'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Hv-jA2bZ2xz"
   },
   "outputs": [],
   "source": [
    "df['source_txt'] = df['source_txt'].astype(str)\n",
    "df['plagarism_txt'] = df['plagarism_txt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "wnFNtuSdRstE",
    "outputId": "c1741a5c-f946-4161-cdd8-cf6eafe3ee69"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3ZoPwI7RuGX"
   },
   "outputs": [],
   "source": [
    "df = df[['source_txt', 'plagarism_txt', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzxh7blAST47",
    "outputId": "1de6d260-f6d2-427b-eca3-1d5d360fe9d0"
   },
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "model_checkpoint = \"aryaumesh/english-to-marathi\"\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_checkpoint)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def translate_en_to_mr(text: str) -> str:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df['source_txt'] = df['source_txt'].progress_apply(translate_en_to_mr)\n",
    "df['plagarism_txt'] = df['plagarism_txt'].progress_apply(translate_en_to_mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Yk19au6TnYh"
   },
   "outputs": [],
   "source": [
    "def getStopWords():\n",
    "  with open('./stopwords-mr.txt','r') as f:\n",
    "    stopwords=f.read()\n",
    "    stopwords=stopwords.split('\\n')\n",
    "    return stopwords\n",
    "\n",
    "stopWords=getStopWords()\n",
    "\n",
    "stop_words = stopWords\n",
    "suffixes = ['ता', 'ते', 'तो', 'ल', 'ना', 'णे', 'त', 'य']\n",
    "def stem_marathi_word(word):\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "noun_suffixes = ['आणि', 'े', 'ा', 'नी', 'ची', 'मधील', 'हवे', 'ची', 'चा']\n",
    "verb_suffixes = ['त', 'तो', 'ते', 'ली', 'ला', 'ले', 'णार', 'त आहे', 'त असतील']\n",
    "def lemmatize_marathi(word):\n",
    "    for suffix in verb_suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "\n",
    "    for suffix in noun_suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "\n",
    "def preprocess_text(text, use_stemming=False, use_lemmatization=False):\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "\n",
    "    cleaned_text = ''.join(char for char in text if ('\\u0900' <= char <= '\\u097F') or char.isspace())\n",
    "\n",
    "\n",
    "    cleaned_text = ' '.join([word for word in cleaned_text.split() if word not in stop_words])\n",
    "\n",
    "\n",
    "    if use_stemming:\n",
    "        cleaned_text = ' '.join([stem_marathi_word(word) for word in cleaned_text.split()])\n",
    "    elif use_lemmatization:\n",
    "        cleaned_text = ' '.join([lemmatize_marathi(word) for word in cleaned_text.split()])\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "df['translated_source'] = df['source_txt'].apply(lambda x: preprocess_text(x))\n",
    "df['translated_plagiarism'] = df['plagarism_txt'].apply(lambda x: preprocess_text(x))\n",
    "df['stemmed_srcText']= df['translated_source'].apply(lambda x: preprocess_text(x,use_stemming=True, use_lemmatization=True))\n",
    "df['stemmed_plagText']=df['translated_plagiarism'].apply(lambda x: preprocess_text(x,use_stemming=True, use_lemmatization=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3anEYAuXW4b"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'l3cube-pune/marathi-sentence-similarity-sbert'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "def get_bert_embeddings():\n",
    "    return model.encode(df['translated_source'].tolist())-model.encode(df['translated_plagiarism'].tolist())\n",
    "\n",
    "bertEmbeddings=get_bert_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-F5GrWfYS_Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_tfidf_embeddings():\n",
    "    tfidf_vectorizer400 = TfidfVectorizer(max_features=400)\n",
    "    return tfidf_vectorizer400.fit_transform(df['stemmed_srcText'].tolist()).toarray()-tfidf_vectorizer400.fit_transform(df['stemmed_plagText'].tolist()).toarray()\n",
    "\n",
    "tfidf_embeddings400 = get_tfidf_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRRYAXJs21T2"
   },
   "source": [
    "# **Proposed Ensemble Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE5MqzfvasaB",
    "outputId": "b3437ef3-1fc1-475e-a12a-90f78af8efe2"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/content/best_tfidf400_classifiers.pkl', 'rb') as tfidf_file:\n",
    "    tfidf_classifiers = pickle.load(tfidf_file)\n",
    "\n",
    "with open('/content/best_bert768_classifiers.pkl', 'rb') as bert_file:\n",
    "    bert_classifiers = pickle.load(bert_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIpRfOUibPaK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tfidf_weights = [0.1, 0.9]\n",
    "bert_weights = [0.7, 0.3]\n",
    "\n",
    "tfidf_predictions = np.array([\n",
    "    weight * clf.predict_proba(tfidf_embeddings400)[:, 1]\n",
    "    for clf, weight in zip(tfidf_classifiers, tfidf_weights)\n",
    "]).sum(axis=0)\n",
    "\n",
    "bert_predictions = np.array([\n",
    "    weight * clf.predict_proba(bertEmbeddings)[:, 1]\n",
    "    for clf, weight in zip(bert_classifiers, bert_weights)\n",
    "]).sum(axis=0)\n",
    "\n",
    "tfidf_predictions = tfidf_predictions.reshape(-1, 1)\n",
    "bert_predictions = bert_predictions.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYWRlvAob50Y"
   },
   "outputs": [],
   "source": [
    "def weighted_ensemble(tfidf_preds, bert_preds):\n",
    "    return (0.4 * tfidf_preds +\n",
    "            0.6 * bert_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VcwFmRSgjzg",
    "outputId": "9b7425b9-a701-4786-c541-b9ea8c725a5e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, roc_auc_score)\n",
    "\n",
    "combined_predictions = weighted_ensemble(tfidf_predictions, bert_predictions)\n",
    "\n",
    "binary_predictions = (combined_predictions >= 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(df[\"label\"], binary_predictions)\n",
    "precision = precision_score(df[\"label\"], binary_predictions)\n",
    "recall = recall_score(df[\"label\"], binary_predictions)\n",
    "f1 = f1_score(df[\"label\"], binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia1tEvk089j0"
   },
   "source": [
    "# **XGboost with BERT-768**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsUcYoeK969i",
    "outputId": "c14b86ea-2e3b-4e0c-f581-c8bb84f34f6d"
   },
   "outputs": [],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5e6m8UNK88dk",
    "outputId": "006fbf9e-abb4-4fdc-b91a-c944e6b575e2"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/content/xgboost_bert768.pkl', 'rb') as f:\n",
    "    bert768_xgboost_model=pickle.load(f)\n",
    "\n",
    "    y_pred = bert768_xgboost_model.predict(bertEmbeddings)\n",
    "\n",
    "    accuracy = accuracy_score(df[\"label\"], y_pred) * 100\n",
    "    precision = precision_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "    recall = recall_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "    f1 = f1_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}%\")\n",
    "    print(f\"Recall: {recall:.2f}%\")\n",
    "    print(f\"F1 Score: {f1:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest with BERT-768**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRe1OwdU95Ov",
    "outputId": "da874bea-92bf-4915-aa70-afdea4322a09"
   },
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "\n",
    "rf_bert768_model = load('/content/rf_bert768.pkl')\n",
    "\n",
    "y_pred = rf_bert768_model.predict(bertEmbeddings)\n",
    "\n",
    "accuracy = accuracy_score(df[\"label\"], y_pred) * 100\n",
    "precision = precision_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "recall = recall_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "f1 = f1_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LIGHTBGM with BERT-768**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYWJJaR6-MWe",
    "outputId": "295454b5-a3f9-4e72-d3aa-c3b15d606c83"
   },
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "\n",
    "lgbm_bert768_model = load('/content/lgbm_bert768.pkl')\n",
    "\n",
    "y_pred = lgbm_bert768_model.predict(bertEmbeddings)\n",
    "\n",
    "accuracy = accuracy_score(df[\"label\"], y_pred) * 100\n",
    "precision = precision_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "recall = recall_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "f1 = f1_score(df[\"label\"], y_pred, average='binary') * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhwtZjYU-5Nc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
